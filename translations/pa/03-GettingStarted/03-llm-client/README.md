<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4d846ebb88fbb0f00549e2ff8cc3f746",
  "translation_date": "2025-10-06T14:05:45+00:00",
  "source_file": "03-GettingStarted/03-llm-client/README.md",
  "language_code": "pa"
}
-->
# LLM ‡®®‡®æ‡®≤ ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®¨‡®£‡®æ‡®â‡®£‡®æ

‡®Ö‡®ú‡©á ‡®§‡©±‡®ï, ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®¶‡©á‡®ñ‡®ø‡®Ü ‡®ï‡®ø ‡®∏‡®∞‡®µ‡®∞ ‡®Ö‡®§‡©á ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®¨‡®£‡®æ‡®â‡®£‡®æ ‡®π‡©à‡•§ ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®®‡©á ‡®∏‡®∞‡®µ‡®∞ ‡®®‡©Ç‡©∞ ‡®∏‡®™‡®∏‡®º‡®ü ‡®§‡©å‡®∞ '‡®§‡©á ‡®ï‡®æ‡®≤ ‡®ï‡®∞‡®ï‡©á ‡®á‡®∏‡®¶‡©á ‡®ü‡©Ç‡®≤, ‡®∏‡®∞‡©ã‡®§ ‡®Ö‡®§‡©á ‡®™‡©ç‡®∞‡©ã‡©∞‡®™‡®ü ‡®¶‡©Ä ‡®∏‡©Ç‡®ö‡©Ä ‡®¨‡®£‡®æ‡®à ‡®π‡©à‡•§ ‡®π‡®æ‡®≤‡®æ‡®Ç‡®ï‡®ø, ‡®á‡®π ‡®¨‡®π‡©Å‡®§ ‡®π‡©Ä ‡®µ‡®ø‡®Ü‡®µ‡®π‡®æ‡®∞‡®ø‡®ï ‡®™‡®π‡©Å‡©∞‡®ö ‡®®‡®π‡©Ä‡®Ç ‡®π‡©à‡•§ ‡®§‡©Å‡®π‡®æ‡®°‡®æ ‡®Ø‡©Ç‡®ú‡®º‡®∞ ‡®è‡®ú‡©∞‡®ü‡®ø‡®ï ‡®Ø‡©Å‡©±‡®ó ‡®µ‡®ø‡©±‡®ö ‡®∞‡®π‡®ø‡©∞‡®¶‡®æ ‡®π‡©à ‡®Ö‡®§‡©á ‡®™‡©ç‡®∞‡©ã‡©∞‡®™‡®ü ‡®µ‡®∞‡®§‡®£ ‡®Ö‡®§‡©á LLM ‡®®‡®æ‡®≤ ‡®∏‡©∞‡®ö‡®æ‡®∞ ‡®ï‡®∞‡®® ‡®¶‡©Ä ‡®â‡®Æ‡©Ä‡®¶ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§ ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®Ø‡©Ç‡®ú‡®º‡®∞ ‡®≤‡®à, ‡®á‡®π ‡®Æ‡®π‡©±‡®§‡®µ‡®™‡©Ç‡®∞‡®® ‡®®‡®π‡©Ä‡®Ç ‡®π‡©à ‡®ï‡®ø ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®Ü‡®™‡®£‡©Ä‡®Ü‡®Ç ‡®∏‡®Æ‡®∞‡©±‡®•‡®æ‡®µ‡®æ‡®Ç ‡®∏‡®ü‡©ã‡®∞ ‡®ï‡®∞‡®® ‡®≤‡®à MCP ‡®µ‡®∞‡®§‡®¶‡©á ‡®π‡©ã ‡®ú‡®æ‡®Ç ‡®®‡®π‡©Ä‡®Ç, ‡®™‡®∞ ‡®â‡®π ‡®ï‡©Å‡®¶‡®∞‡®§‡©Ä ‡®≠‡®æ‡®∏‡®º‡®æ ‡®µ‡®∞‡®§ ‡®ï‡©á ‡®∏‡©∞‡®ö‡®æ‡®∞ ‡®ï‡®∞‡®® ‡®¶‡©Ä ‡®â‡®Æ‡©Ä‡®¶ ‡®ï‡®∞‡®¶‡©á ‡®π‡®®‡•§ ‡®§‡®æ‡®Ç ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡®∏‡®®‡©Ç‡©∞ ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®π‡©±‡®≤ ‡®ï‡®∞‡©Ä‡®è? ‡®π‡©±‡®≤ ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®µ‡®ø‡©±‡®ö LLM ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡®® ‡®¨‡®æ‡®∞‡©á ‡®π‡©à‡•§

## ‡®ù‡®≤‡®ï

‡®á‡®∏ ‡®™‡®æ‡®† ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®µ‡®ø‡©±‡®ö LLM ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡®® '‡®§‡©á ‡®ß‡®ø‡®Ü‡®® ‡®¶‡®ø‡©∞‡®¶‡©á ‡®π‡®æ‡®Ç ‡®Ö‡®§‡©á ‡®¶‡®ø‡®ñ‡®æ‡®â‡®Ç‡®¶‡©á ‡®π‡®æ‡®Ç ‡®ï‡®ø ‡®á‡®π ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®Ø‡©Ç‡®ú‡®º‡®∞ ‡®≤‡®à ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®¨‡®ø‡®π‡®§‡®∞ ‡®Ö‡®®‡©Å‡®≠‡®µ ‡®™‡©ç‡®∞‡®¶‡®æ‡®® ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§

## ‡®∏‡®ø‡©±‡®ñ‡®£ ‡®¶‡©á ‡®â‡®¶‡©á‡®∏‡®º

‡®á‡®∏ ‡®™‡®æ‡®† ‡®¶‡©á ‡®Ö‡©∞‡®§ ‡®§‡©±‡®ï, ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®á‡®π ‡®ï‡®∞‡®® ‡®¶‡©á ‡®Ø‡©ã‡®ó ‡®π‡©ã‡®µ‡©ã‡®ó‡©á:

- LLM ‡®®‡®æ‡®≤ ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®¨‡®£‡®æ‡®â‡®£‡®æ‡•§
- LLM ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á MCP ‡®∏‡®∞‡®µ‡®∞ ‡®®‡®æ‡®≤ ‡®¨‡®ø‡®®‡®æ‡®Ç ‡®∞‡©Å‡®ï‡®æ‡®µ‡®ü ‡®∏‡©∞‡®ö‡®æ‡®∞ ‡®ï‡®∞‡®®‡®æ‡•§
- ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®™‡®æ‡®∏‡©á ‡®¨‡®ø‡®π‡®§‡®∞ ‡®Ö‡©∞‡®§ ‡®Ø‡©Ç‡®ú‡®º‡®∞ ‡®Ö‡®®‡©Å‡®≠‡®µ ‡®™‡©ç‡®∞‡®¶‡®æ‡®® ‡®ï‡®∞‡®®‡®æ‡•§

## ‡®™‡®π‡©Å‡©∞‡®ö

‡®Ü‡®ì ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®Æ‡®ù‡®£ ‡®¶‡©Ä ‡®ï‡©ã‡®∏‡®º‡®ø‡®∏‡®º ‡®ï‡®∞‡©Ä‡®è ‡®ï‡®ø ‡®∏‡®æ‡®®‡©Ç‡©∞ ‡®ï‡®ø‡®π‡©ú‡©Ä ‡®™‡®π‡©Å‡©∞‡®ö ‡®≤‡©à‡®£‡©Ä ‡®ö‡®æ‡®π‡©Ä‡®¶‡©Ä ‡®π‡©à‡•§ LLM ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡®®‡®æ ‡®∏‡®ß‡®æ‡®∞‡®® ‡®≤‡©±‡®ó‡®¶‡®æ ‡®π‡©à, ‡®™‡®∞ ‡®ï‡©Ä ‡®Ö‡®∏‡©Ä‡®Ç ‡®µ‡®æ‡®∏‡®§‡®µ ‡®µ‡®ø‡©±‡®ö ‡®á‡®π ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç?

‡®á‡®π ‡®π‡©à ‡®ï‡®ø ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®∏‡®∞‡®µ‡®∞ ‡®®‡®æ‡®≤ ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®∏‡©∞‡®ö‡®æ‡®∞ ‡®ï‡®∞‡©á‡®ó‡®æ:

1. ‡®∏‡®∞‡®µ‡®∞ ‡®®‡®æ‡®≤ ‡®ï‡®®‡©à‡®ï‡®∏‡®º‡®® ‡®∏‡®•‡®æ‡®™‡®§ ‡®ï‡®∞‡©ã‡•§

1. ‡®∏‡®Æ‡®∞‡©±‡®•‡®æ‡®µ‡®æ‡®Ç, ‡®™‡©ç‡®∞‡©ã‡©∞‡®™‡®ü, ‡®∏‡®∞‡©ã‡®§ ‡®Ö‡®§‡©á ‡®ü‡©Ç‡®≤ ‡®¶‡©Ä ‡®∏‡©Ç‡®ö‡©Ä ‡®¨‡®£‡®æ‡®ì ‡®Ö‡®§‡©á ‡®â‡®®‡©ç‡®π‡®æ‡®Ç ‡®¶‡©Ä ‡®∏‡®ï‡©Ä‡®Æ‡®æ ‡®∏‡©á‡®µ ‡®ï‡®∞‡©ã‡•§

1. ‡®á‡©±‡®ï LLM ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã ‡®Ö‡®§‡©á ‡®∏‡©á‡®µ ‡®ï‡©Ä‡®§‡©Ä‡®Ü‡®Ç ‡®∏‡®Æ‡®∞‡©±‡®•‡®æ‡®µ‡®æ‡®Ç ‡®Ö‡®§‡©á ‡®â‡®®‡©ç‡®π‡®æ‡®Ç ‡®¶‡©Ä ‡®∏‡®ï‡©Ä‡®Æ‡®æ ‡®®‡©Ç‡©∞ ‡®á‡©±‡®ï ‡®´‡®æ‡®∞‡®Æ‡©à‡®ü ‡®µ‡®ø‡©±‡®ö ‡®™‡®æ‡®∏ ‡®ï‡®∞‡©ã ‡®ú‡©ã LLM ‡®®‡©Ç‡©∞ ‡®∏‡®Æ‡®ù ‡®Ü‡®â‡®Ç‡®¶‡®æ ‡®π‡©à‡•§

1. ‡®Ø‡©Ç‡®ú‡®º‡®∞ ‡®™‡©ç‡®∞‡©ã‡©∞‡®™‡®ü ‡®®‡©Ç‡©∞ LLM ‡®®‡©Ç‡©∞ ‡®™‡®æ‡®∏ ‡®ï‡®∞‡®ï‡©á ‡®∏‡©∞‡®≠‡®æ‡®≤‡©ã, ‡®®‡®æ‡®≤ ‡®π‡©Ä ‡®â‡®π ‡®ü‡©Ç‡®≤ ‡®ú‡©ã ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®¶‡©Å‡®Ü‡®∞‡®æ ‡®∏‡©Ç‡®ö‡©Ä‡®¨‡©±‡®ß ‡®ï‡©Ä‡®§‡©á ‡®ó‡®è ‡®π‡®®‡•§

‡®µ‡®ß‡©Ä‡®Ü, ‡®π‡©Å‡®£ ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®Æ‡®ù ‡®ó‡®è ‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡®∏‡®®‡©Ç‡©∞ ‡®â‡©±‡®ö ‡®™‡©±‡®ß‡®∞ '‡®§‡©á ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç, ‡®Ü‡®ì ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡©á ‡®Ö‡®≠‡®ø‡®Ü‡®∏ ‡®µ‡®ø‡©±‡®ö ‡®á‡®∏‡®®‡©Ç‡©∞ ‡®Ö‡®ú‡®º‡®Æ‡®æ‡®à‡®è‡•§

## ‡®Ö‡®≠‡®ø‡®Ü‡®∏: LLM ‡®®‡®æ‡®≤ ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®¨‡®£‡®æ‡®â‡®£‡®æ

‡®á‡®∏ ‡®Ö‡®≠‡®ø‡®Ü‡®∏ ‡®µ‡®ø‡©±‡®ö, ‡®Ö‡®∏‡©Ä‡®Ç ‡®Ü‡®™‡®£‡©á ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®µ‡®ø‡©±‡®ö LLM ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡®®‡®æ ‡®∏‡®ø‡©±‡®ñ‡®æ‡®Ç‡®ó‡©á‡•§

### GitHub Personal Access Token ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®™‡©ç‡®∞‡®Æ‡®æ‡®£‡®ø‡®ï‡®§‡®æ

GitHub ‡®ü‡©ã‡®ï‡®® ‡®¨‡®£‡®æ‡®â‡®£‡®æ ‡®á‡©±‡®ï ‡®∏‡®ß‡®æ‡®∞‡®® ‡®™‡©ç‡®∞‡®ï‡®ø‡®∞‡®ø‡®Ü ‡®π‡©à‡•§ ‡®á‡®π ‡®π‡©à ‡®ï‡®ø ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®á‡®∏‡®®‡©Ç‡©∞ ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã:

- GitHub ‡®∏‡©à‡®ü‡®ø‡©∞‡®ó‡®ú‡®º '‡®§‡©á ‡®ú‡®æ‡®ì ‚Äì ‡®Ü‡®™‡®£‡©á ‡®™‡©ç‡®∞‡©ã‡®´‡®æ‡®à‡®≤ ‡®§‡®∏‡®µ‡©Ä‡®∞ '‡®§‡©á ‡®ï‡®≤‡®ø‡©±‡®ï ‡®ï‡®∞‡©ã ‡®Ö‡®§‡©á ‡®∏‡©à‡®ü‡®ø‡©∞‡®ó‡®ú‡®º ‡®ö‡©Å‡®£‡©ã‡•§
- Developer Settings '‡®§‡©á ‡®ú‡®æ‡®ì ‚Äì ‡®π‡©á‡®†‡®æ‡®Ç ‡®∏‡®ï‡©ç‡®∞‡©ã‡®≤ ‡®ï‡®∞‡©ã ‡®Ö‡®§‡©á Developer Settings '‡®§‡©á ‡®ï‡®≤‡®ø‡©±‡®ï ‡®ï‡®∞‡©ã‡•§
- Personal Access Tokens ‡®ö‡©Å‡®£‡©ã ‚Äì Fine-grained tokens '‡®§‡©á ‡®ï‡®≤‡®ø‡©±‡®ï ‡®ï‡®∞‡©ã ‡®Ö‡®§‡©á ‡®®‡®µ‡®æ‡®Ç ‡®ü‡©ã‡®ï‡®® ‡®¨‡®£‡®æ‡®ì‡•§
- ‡®Ü‡®™‡®£‡©á ‡®ü‡©ã‡®ï‡®® ‡®®‡©Ç‡©∞ ‡®ï‡®®‡®´‡®ø‡®ó‡®∞ ‡®ï‡®∞‡©ã ‚Äì ‡®π‡®µ‡®æ‡®≤‡©á ‡®≤‡®à ‡®á‡©±‡®ï ‡®®‡©ã‡®ü ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã, ‡®Æ‡®ø‡®Ü‡®¶ ‡®¶‡©Ä ‡®Æ‡®ø‡®§‡©Ä ‡®∏‡©à‡®ü ‡®ï‡®∞‡©ã, ‡®Ö‡®§‡©á ‡®ú‡®º‡®∞‡©Ç‡®∞‡©Ä ‡®∏‡®ï‡©ã‡®™ (‡®Ö‡®ß‡®ø‡®ï‡®æ‡®∞) ‡®ö‡©Å‡®£‡©ã‡•§ ‡®á‡®∏ ‡®Æ‡®æ‡®Æ‡®≤‡©á ‡®µ‡®ø‡©±‡®ö ‡®Ø‡®ï‡©Ä‡®®‡©Ä ‡®¨‡®£‡®æ‡®ì ‡®ï‡®ø Models ‡®Ö‡®ß‡®ø‡®ï‡®æ‡®∞ ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡©Ä‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à‡•§
- ‡®ü‡©ã‡®ï‡®® ‡®¨‡®£‡®æ‡®ì ‡®Ö‡®§‡©á ‡®ï‡®æ‡®™‡©Ä ‡®ï‡®∞‡©ã ‚Äì Generate token '‡®§‡©á ‡®ï‡®≤‡®ø‡©±‡®ï ‡®ï‡®∞‡©ã, ‡®Ö‡®§‡©á ‡®Ø‡®ï‡©Ä‡®®‡©Ä ‡®¨‡®£‡®æ‡®ì ‡®ï‡®ø ‡®á‡®∏‡®®‡©Ç‡©∞ ‡®§‡©Å‡®∞‡©∞‡®§ ‡®ï‡®æ‡®™‡©Ä ‡®ï‡®∞ ‡®≤‡®ì, ‡®ï‡®ø‡®â‡®Ç‡®ï‡®ø ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®á‡®∏‡®®‡©Ç‡©∞ ‡®¶‡©Å‡®¨‡®æ‡®∞‡®æ ‡®®‡®π‡©Ä‡®Ç ‡®¶‡©á‡®ñ ‡®∏‡®ï‡®¶‡©á‡•§

### -1- ‡®∏‡®∞‡®µ‡®∞ ‡®®‡®æ‡®≤ ‡®ï‡®®‡©à‡®ï‡®ü ‡®ï‡®∞‡©ã

‡®Ü‡®ì ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç ‡®Ü‡®™‡®£‡®æ ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®¨‡®£‡®æ‡®à‡®è:

#### TypeScript

```typescript
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import { Transport } from "@modelcontextprotocol/sdk/shared/transport.js";
import OpenAI from "openai";
import { z } from "zod"; // Import zod for schema validation

class MCPClient {
    private openai: OpenAI;
    private client: Client;
    constructor(){
        this.openai = new OpenAI({
            baseURL: "https://models.inference.ai.azure.com", 
            apiKey: process.env.GITHUB_TOKEN,
        });

        this.client = new Client(
            {
                name: "example-client",
                version: "1.0.0"
            },
            {
                capabilities: {
                prompts: {},
                resources: {},
                tools: {}
                }
            }
            );    
    }
}
```

‡®â‡®™‡®∞‡©ã‡®ï‡®§ ‡®ï‡©ã‡®° ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç:

- ‡®≤‡©ã‡©ú‡©Ä‡®Ç‡®¶‡©á ‡®≤‡®æ‡®á‡®¨‡©ç‡®∞‡©á‡®∞‡©Ä‡®ú‡®º ‡®á‡©∞‡®™‡©ã‡®∞‡®ü ‡®ï‡©Ä‡®§‡©á ‡®π‡®®‡•§
- ‡®¶‡©ã ‡®Æ‡©à‡®Ç‡®¨‡®∞‡®æ‡®Ç `client` ‡®Ö‡®§‡©á `openai` ‡®®‡®æ‡®≤ ‡®á‡©±‡®ï ‡®ï‡®≤‡®æ‡®∏ ‡®¨‡®£‡®æ‡®à ‡®π‡©à ‡®ú‡©ã ‡®∏‡®æ‡®®‡©Ç‡©∞ ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®®‡©Ç‡©∞ ‡®Æ‡©à‡®®‡©á‡®ú ‡®ï‡®∞‡®® ‡®Ö‡®§‡©á LLM ‡®®‡®æ‡®≤ ‡®∏‡©∞‡®ö‡®æ‡®∞ ‡®ï‡®∞‡®® ‡®µ‡®ø‡©±‡®ö ‡®Æ‡®¶‡®¶ ‡®ï‡®∞‡©á‡®ó‡®æ‡•§
- GitHub Models ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®® ‡®≤‡®à `baseUrl` ‡®®‡©Ç‡©∞ inference API ‡®µ‡©±‡®≤ ‡®™‡©ã‡®á‡©∞‡®ü ‡®ï‡®∞‡®ï‡©á ‡®Ü‡®™‡®£‡©á LLM ‡®á‡©∞‡®∏‡®ü‡©à‡®Ç‡®∏ ‡®®‡©Ç‡©∞ ‡®ï‡®®‡®´‡®ø‡®ó‡®∞ ‡®ï‡©Ä‡®§‡®æ ‡®π‡©à‡•§

#### Python

```python
from mcp import ClientSession, StdioServerParameters, types
from mcp.client.stdio import stdio_client

# Create server parameters for stdio connection
server_params = StdioServerParameters(
    command="mcp",  # Executable
    args=["run", "server.py"],  # Optional command line arguments
    env=None,  # Optional environment variables
)


async def run():
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(
            read, write
        ) as session:
            # Initialize the connection
            await session.initialize()


if __name__ == "__main__":
    import asyncio

    asyncio.run(run())

```

‡®â‡®™‡®∞‡©ã‡®ï‡®§ ‡®ï‡©ã‡®° ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç:

- MCP ‡®≤‡®à ‡®≤‡©ã‡©ú‡©Ä‡®Ç‡®¶‡©á ‡®≤‡®æ‡®á‡®¨‡©ç‡®∞‡©á‡®∞‡©Ä‡®ú‡®º ‡®á‡©∞‡®™‡©ã‡®∞‡®ü ‡®ï‡©Ä‡®§‡©á ‡®π‡®®‡•§
- ‡®á‡©±‡®ï ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®¨‡®£‡®æ‡®á‡®Ü ‡®π‡©à‡•§

#### .NET

```csharp
using Azure;
using Azure.AI.Inference;
using Azure.Identity;
using System.Text.Json;
using ModelContextProtocol.Client;
using ModelContextProtocol.Protocol.Transport;
using System.Text.Json;

var clientTransport = new StdioClientTransport(new()
{
    Name = "Demo Server",
    Command = "/workspaces/mcp-for-beginners/03-GettingStarted/02-client/solution/server/bin/Debug/net8.0/server",
    Arguments = [],
});

await using var mcpClient = await McpClientFactory.CreateAsync(clientTransport);
```

#### Java

‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç, ‡®§‡©Å‡®π‡®æ‡®®‡©Ç‡©∞ ‡®Ü‡®™‡®£‡©á `pom.xml` ‡®´‡®æ‡®à‡®≤ ‡®µ‡®ø‡©±‡®ö LangChain4j dependencies ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡®® ‡®¶‡©Ä ‡®≤‡©ã‡©ú ‡®π‡©ã‡®µ‡©á‡®ó‡©Ä‡•§ MCP ‡®á‡©∞‡®ü‡©Ä‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®® ‡®Ö‡®§‡©á GitHub Models ‡®∏‡®™‡©ã‡®∞‡®ü ‡®®‡©Ç‡©∞ ‡®Ø‡®ï‡©Ä‡®®‡©Ä ‡®¨‡®£‡®æ‡®â‡®£ ‡®≤‡®à ‡®á‡®π dependencies ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã:

```xml
<properties>
    <langchain4j.version>1.0.0-beta3</langchain4j.version>
</properties>

<dependencies>
    <!-- LangChain4j MCP Integration -->
    <dependency>
        <groupId>dev.langchain4j</groupId>
        <artifactId>langchain4j-mcp</artifactId>
        <version>${langchain4j.version}</version>
    </dependency>
    
    <!-- OpenAI Official API Client -->
    <dependency>
        <groupId>dev.langchain4j</groupId>
        <artifactId>langchain4j-open-ai-official</artifactId>
        <version>${langchain4j.version}</version>
    </dependency>
    
    <!-- GitHub Models Support -->
    <dependency>
        <groupId>dev.langchain4j</groupId>
        <artifactId>langchain4j-github-models</artifactId>
        <version>${langchain4j.version}</version>
    </dependency>
    
    <!-- Spring Boot Starter (optional, for production apps) -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-actuator</artifactId>
    </dependency>
</dependencies>
```

‡®´‡®ø‡®∞ ‡®Ü‡®™‡®£‡©Ä Java ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®ï‡®≤‡®æ‡®∏ ‡®¨‡®£‡®æ‡®ì:

```java
import dev.langchain4j.mcp.McpToolProvider;
import dev.langchain4j.mcp.client.DefaultMcpClient;
import dev.langchain4j.mcp.client.McpClient;
import dev.langchain4j.mcp.client.transport.McpTransport;
import dev.langchain4j.mcp.client.transport.http.HttpMcpTransport;
import dev.langchain4j.model.chat.ChatLanguageModel;
import dev.langchain4j.model.openaiofficial.OpenAiOfficialChatModel;
import dev.langchain4j.service.AiServices;
import dev.langchain4j.service.tool.ToolProvider;

import java.time.Duration;
import java.util.List;

public class LangChain4jClient {
    
    public static void main(String[] args) throws Exception {        // Configure the LLM to use GitHub Models
        ChatLanguageModel model = OpenAiOfficialChatModel.builder()
                .isGitHubModels(true)
                .apiKey(System.getenv("GITHUB_TOKEN"))
                .timeout(Duration.ofSeconds(60))
                .modelName("gpt-4.1-nano")
                .build();

        // Create MCP transport for connecting to server
        McpTransport transport = new HttpMcpTransport.Builder()
                .sseUrl("http://localhost:8080/sse")
                .timeout(Duration.ofSeconds(60))
                .logRequests(true)
                .logResponses(true)
                .build();

        // Create MCP client
        McpClient mcpClient = new DefaultMcpClient.Builder()
                .transport(transport)
                .build();
    }
}
```

‡®â‡®™‡®∞‡©ã‡®ï‡®§ ‡®ï‡©ã‡®° ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç:

- **LangChain4j dependencies ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡©Ä‡®§‡©á**: MCP ‡®á‡©∞‡®ü‡©Ä‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®®, OpenAI ‡®Ö‡®ß‡®ø‡®ï‡®æ‡®∞‡®§ ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü, ‡®Ö‡®§‡©á GitHub Models ‡®∏‡®™‡©ã‡®∞‡®ü ‡®≤‡®à ‡®≤‡©ã‡©ú‡©Ä‡®Ç‡®¶‡©á‡•§
- **LangChain4j ‡®≤‡®æ‡®á‡®¨‡©ç‡®∞‡©á‡®∞‡©Ä‡®ú‡®º ‡®á‡©∞‡®™‡©ã‡®∞‡®ü ‡®ï‡©Ä‡®§‡©Ä‡®Ü‡®Ç**: MCP ‡®á‡©∞‡®ü‡©Ä‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®® ‡®Ö‡®§‡©á OpenAI ‡®ö‡©à‡®ü ‡®Æ‡®æ‡®°‡®≤ ‡®´‡©∞‡®ï‡®∏‡®º‡®®‡®≤‡®ø‡®ü‡©Ä ‡®≤‡®à‡•§
- **`ChatLanguageModel` ‡®¨‡®£‡®æ‡®á‡®Ü**: GitHub Models ‡®®‡®æ‡®≤ GitHub ‡®ü‡©ã‡®ï‡®® ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®® ‡®≤‡®à ‡®ï‡®®‡®´‡®ø‡®ó‡®∞ ‡®ï‡©Ä‡®§‡®æ‡•§
- **HTTP ‡®ü‡©ç‡®∞‡®æ‡®Ç‡®∏‡®™‡©ã‡®∞‡®ü ‡®∏‡©à‡®ü ‡®ï‡©Ä‡®§‡®æ**: Server-Sent Events (SSE) ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á MCP ‡®∏‡®∞‡®µ‡®∞ ‡®®‡®æ‡®≤ ‡®ï‡®®‡©à‡®ï‡®ü ‡®ï‡®∞‡®® ‡®≤‡®à‡•§
- **MCP ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®¨‡®£‡®æ‡®á‡®Ü**: ‡®ú‡©ã ‡®∏‡®∞‡®µ‡®∞ ‡®®‡®æ‡®≤ ‡®∏‡©∞‡®ö‡®æ‡®∞ ‡®®‡©Ç‡©∞ ‡®∏‡©∞‡®≠‡®æ‡®≤‡©á‡®ó‡®æ‡•§
- **LangChain4j ‡®¶‡©Ä ‡®¨‡®£‡®æ‡®à MCP ‡®∏‡®™‡©ã‡®∞‡®ü ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡©Ä‡®§‡©Ä**: ‡®ú‡©ã LLMs ‡®Ö‡®§‡©á MCP ‡®∏‡®∞‡®µ‡®∞‡®æ‡®Ç ‡®¶‡©á ‡®µ‡®ø‡®ö‡®ï‡®æ‡®∞ ‡®á‡©∞‡®ü‡©Ä‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®® ‡®®‡©Ç‡©∞ ‡®∏‡®ß‡®æ‡®∞‡®® ‡®¨‡®£‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à‡•§

#### Rust

‡®á‡®π ‡®â‡®¶‡®æ‡®π‡®∞‡®£ ‡®Æ‡©∞‡®®‡®¶‡®æ ‡®π‡©à ‡®ï‡®ø ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®ï‡©ã‡®≤ Rust ‡®Ö‡®ß‡®æ‡®∞‡®ø‡®§ MCP ‡®∏‡®∞‡®µ‡®∞ ‡®ö‡©±‡®≤ ‡®∞‡®ø‡®π‡®æ ‡®π‡©à‡•§ ‡®ú‡©á ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®ï‡©ã‡®≤ ‡®®‡®π‡©Ä‡®Ç ‡®π‡©à, ‡®§‡®æ‡®Ç [01-first-server](../01-first-server/README.md) ‡®™‡®æ‡®† ‡®µ‡®ø‡©±‡®ö ‡®µ‡®æ‡®™‡®∏ ‡®ú‡®æ‡®ì ‡®Ö‡®§‡©á ‡®∏‡®∞‡®µ‡®∞ ‡®¨‡®£‡®æ‡®ì‡•§

‡®ú‡®¶‡©ã‡®Ç ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®ï‡©ã‡®≤ Rust MCP ‡®∏‡®∞‡®µ‡®∞ ‡®π‡©ã‡®µ‡©á, ‡®ü‡®∞‡®Æ‡©Ä‡®®‡®≤ ‡®ñ‡©ã‡®≤‡©ç‡®π‡©ã ‡®Ö‡®§‡©á ‡®∏‡®∞‡®µ‡®∞ ‡®µ‡®æ‡®≤‡©á ‡®°‡®æ‡®á‡®∞‡©à‡®ï‡®ü‡®∞‡©Ä ‡®µ‡®ø‡©±‡®ö ‡®ú‡®æ‡®ì‡•§ ‡®´‡®ø‡®∞ ‡®®‡®µ‡®æ‡®Ç LLM ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®™‡©ç‡®∞‡©ã‡®ú‡©à‡®ï‡®ü ‡®¨‡®£‡®æ‡®â‡®£ ‡®≤‡®à ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡©á ‡®ï‡®Æ‡®æ‡®Ç‡®° ‡®ö‡®≤‡®æ‡®ì:

```bash
mkdir calculator-llmclient
cd calculator-llmclient
cargo init
```

‡®Ü‡®™‡®£‡©á `Cargo.toml` ‡®´‡®æ‡®à‡®≤ ‡®µ‡®ø‡©±‡®ö ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡©Ä‡®Ü‡®Ç dependencies ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã:

```toml
[dependencies]
async-openai = { version = "0.29.0", features = ["byot"] }
rmcp = { version = "0.5.0", features = ["client", "transport-child-process"] }
serde_json = "1.0.141"
tokio = { version = "1.46.1", features = ["rt-multi-thread"] }
```

> [!NOTE]
> Rust ‡®≤‡®à OpenAI ‡®¶‡©Ä ‡®Ö‡®ß‡®ø‡®ï‡®æ‡®∞‡®§ ‡®≤‡®æ‡®á‡®¨‡©ç‡®∞‡©á‡®∞‡©Ä ‡®®‡®π‡©Ä‡®Ç ‡®π‡©à, ‡®π‡®æ‡®≤‡®æ‡®Ç‡®ï‡®ø `async-openai` crate ‡®á‡©±‡®ï [community maintained library](https://platform.openai.com/docs/libraries/rust#rust) ‡®π‡©à ‡®ú‡©ã ‡®Ü‡®Æ ‡®§‡©å‡®∞ '‡®§‡©á ‡®µ‡®∞‡®§‡©Ä ‡®ú‡®æ‡®Ç‡®¶‡©Ä ‡®π‡©à‡•§

`src/main.rs` ‡®´‡®æ‡®à‡®≤ ‡®ñ‡©ã‡®≤‡©ç‡®π‡©ã ‡®Ö‡®§‡©á ‡®á‡®∏‡®¶‡©Ä ‡®∏‡®Æ‡©±‡®ó‡®∞‡©Ä ‡®®‡©Ç‡©∞ ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡©á ‡®ï‡©ã‡®° ‡®®‡®æ‡®≤ ‡®¨‡®¶‡®≤‡©ã:

```rust
use async_openai::{Client, config::OpenAIConfig};
use rmcp::{
    RmcpError,
    model::{CallToolRequestParam, ListToolsResult},
    service::{RoleClient, RunningService, ServiceExt},
    transport::{ConfigureCommandExt, TokioChildProcess},
};
use serde_json::{Value, json};
use std::error::Error;
use tokio::process::Command;

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    // Initial message
    let mut messages = vec![json!({"role": "user", "content": "What is the sum of 3 and 2?"})];

    // Setup OpenAI client
    let api_key = std::env::var("OPENAI_API_KEY")?;
    let openai_client = Client::with_config(
        OpenAIConfig::new()
            .with_api_base("https://models.github.ai/inference/chat")
            .with_api_key(api_key),
    );

    // Setup MCP client
    let server_dir = std::path::Path::new(env!("CARGO_MANIFEST_DIR"))
        .parent()
        .unwrap()
        .join("calculator-server");

    let mcp_client = ()
        .serve(
            TokioChildProcess::new(Command::new("cargo").configure(|cmd| {
                cmd.arg("run").current_dir(server_dir);
            }))
            .map_err(RmcpError::transport_creation::<TokioChildProcess>)?,
        )
        .await?;

    // TODO: Get MCP tool listing 

    // TODO: LLM conversation with tool calls

    Ok(())
}
```

‡®á‡®π ‡®ï‡©ã‡®° ‡®á‡©±‡®ï ‡®¨‡©Å‡®®‡®ø‡®Ü‡®¶‡©Ä Rust ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®∏‡©à‡®ü ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à ‡®ú‡©ã MCP ‡®∏‡®∞‡®µ‡®∞ ‡®Ö‡®§‡©á GitHub Models ‡®®‡®æ‡®≤ LLM ‡®á‡©∞‡®ü‡®∞‡©à‡®ï‡®∏‡®º‡®® ‡®≤‡®à ‡®ï‡®®‡©à‡®ï‡®ü ‡®ï‡®∞‡©á‡®ó‡®æ‡•§

> [!IMPORTANT]
> ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®ö‡®≤‡®æ‡®â‡®£ ‡®§‡©ã‡®Ç ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç `OPENAI_API_KEY` ‡®µ‡®æ‡®§‡®æ‡®µ‡®∞‡®£ ‡®µ‡©à‡®∞‡©Ä‡®è‡®¨‡®≤ ‡®®‡©Ç‡©∞ ‡®Ü‡®™‡®£‡©á GitHub ‡®ü‡©ã‡®ï‡®® ‡®®‡®æ‡®≤ ‡®∏‡©à‡®ü ‡®ï‡®∞‡©ã‡•§

‡®µ‡®ß‡©Ä‡®Ü, ‡®Ö‡®ó‡®≤‡©á ‡®ï‡®¶‡®Æ ‡®µ‡®ø‡©±‡®ö, ‡®Ü‡®ì ‡®∏‡®∞‡®µ‡®∞ ‡®¶‡©Ä ‡®∏‡®Æ‡®∞‡©±‡®•‡®æ‡®µ‡®æ‡®Ç ‡®¶‡©Ä ‡®∏‡©Ç‡®ö‡©Ä ‡®¨‡®£‡®æ‡®à‡®è‡•§

### -2- ‡®∏‡®∞‡®µ‡®∞ ‡®¶‡©Ä ‡®∏‡®Æ‡®∞‡©±‡®•‡®æ‡®µ‡®æ‡®Ç ‡®¶‡©Ä ‡®∏‡©Ç‡®ö‡©Ä ‡®¨‡®£‡®æ‡®â‡®£‡®æ

‡®π‡©Å‡®£ ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®∞‡®µ‡®∞ ‡®®‡®æ‡®≤ ‡®ï‡®®‡©à‡®ï‡®ü ‡®ï‡®∞‡®æ‡®Ç‡®ó‡©á ‡®Ö‡®§‡©á ‡®á‡®∏ ‡®¶‡©Ä ‡®∏‡®Æ‡®∞‡©±‡®•‡®æ‡®µ‡®æ‡®Ç ‡®¶‡©Ä ‡®¨‡©á‡®®‡®§‡©Ä ‡®ï‡®∞‡®æ‡®Ç‡®ó‡©á:

#### TypeScript

‡®â‡®∏‡©á ‡®ï‡®≤‡®æ‡®∏ ‡®µ‡®ø‡©±‡®ö ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡©á ‡®Æ‡©à‡®•‡®° ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã:

```typescript
async connectToServer(transport: Transport) {
     await this.client.connect(transport);
     this.run();
     console.error("MCPClient started on stdin/stdout");
}

async run() {
    console.log("Asking server for available tools");

    // listing tools
    const toolsResult = await this.client.listTools();
}
```

‡®â‡®™‡®∞‡©ã‡®ï‡®§ ‡®ï‡©ã‡®° ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç:

- ‡®∏‡®∞‡®µ‡®∞ ‡®®‡®æ‡®≤ ‡®ï‡®®‡©à‡®ï‡®ü ‡®ï‡®∞‡®® ‡®≤‡®à ‡®ï‡©ã‡®° ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡©Ä‡®§‡®æ, `connectToServer`‡•§
- ‡®á‡©±‡®ï `run` ‡®Æ‡©à‡®•‡®° ‡®¨‡®£‡®æ‡®á‡®Ü ‡®ú‡©ã ‡®∏‡®æ‡®°‡©á ‡®ê‡®™ ‡®´‡®≤‡©ã ‡®®‡©Ç‡©∞ ‡®∏‡©∞‡®≠‡®æ‡®≤‡®£ ‡®≤‡®à ‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞ ‡®π‡©à‡•§ ‡®π‡©Å‡®£ ‡®§‡©±‡®ï ‡®á‡®π ‡®∏‡®ø‡®∞‡®´ ‡®ü‡©Ç‡®≤ ‡®¶‡©Ä ‡®∏‡©Ç‡®ö‡©Ä ‡®¨‡®£‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à ‡®™‡®∞ ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡®∏ ‡®µ‡®ø‡©±‡®ö ‡®ú‡®≤‡®¶‡©Ä ‡®π‡©ã‡®∞ ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡®æ‡®Ç‡®ó‡©á‡•§

#### Python

```python
# List available resources
resources = await session.list_resources()
print("LISTING RESOURCES")
for resource in resources:
    print("Resource: ", resource)

# List available tools
tools = await session.list_tools()
print("LISTING TOOLS")
for tool in tools.tools:
    print("Tool: ", tool.name)
    print("Tool", tool.inputSchema["properties"])
```

‡®á‡®π ‡®π‡©à ‡®ú‡©ã ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡©Ä‡®§‡®æ:

- ‡®∏‡®∞‡©ã‡®§ ‡®Ö‡®§‡©á ‡®ü‡©Ç‡®≤ ‡®¶‡©Ä ‡®∏‡©Ç‡®ö‡©Ä ‡®¨‡®£‡®æ‡®à ‡®Ö‡®§‡©á ‡®™‡©ç‡®∞‡®ø‡©∞‡®ü ‡®ï‡©Ä‡®§‡©á‡•§ ‡®ü‡©Ç‡®≤ ‡®≤‡®à ‡®Ö‡®∏‡©Ä‡®Ç `inputSchema` ‡®¶‡©Ä ‡®µ‡©Ä ‡®∏‡©Ç‡®ö‡©Ä ‡®¨‡®£‡®æ‡®à ‡®ú‡©ã ‡®Ö‡®∏‡©Ä‡®Ç ‡®¨‡®æ‡®Ö‡®¶ ‡®µ‡®ø‡©±‡®ö ‡®µ‡®∞‡®§‡®¶‡©á ‡®π‡®æ‡®Ç‡•§

#### .NET

```csharp
async Task<List<ChatCompletionsToolDefinition>> GetMcpTools()
{
    Console.WriteLine("Listing tools");
    var tools = await mcpClient.ListToolsAsync();

    List<ChatCompletionsToolDefinition> toolDefinitions = new List<ChatCompletionsToolDefinition>();

    foreach (var tool in tools)
    {
        Console.WriteLine($"Connected to server with tools: {tool.Name}");
        Console.WriteLine($"Tool description: {tool.Description}");
        Console.WriteLine($"Tool parameters: {tool.JsonSchema}");

        // TODO: convert tool definition from MCP tool to LLm tool     
    }

    return toolDefinitions;
}
```

‡®â‡®™‡®∞‡©ã‡®ï‡®§ ‡®ï‡©ã‡®° ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç:

- MCP ‡®∏‡®∞‡®µ‡®∞ '‡®§‡©á ‡®â‡®™‡®≤‡®¨‡®ß ‡®ü‡©Ç‡®≤ ‡®¶‡©Ä ‡®∏‡©Ç‡®ö‡©Ä ‡®¨‡®£‡®æ‡®à‡•§
- ‡®π‡®∞ ‡®ü‡©Ç‡®≤ ‡®≤‡®à, ‡®®‡®æ‡®Æ, ‡®µ‡©á‡®∞‡®µ‡®æ ‡®Ö‡®§‡©á ‡®á‡®∏‡®¶‡©Ä ‡®∏‡®ï‡©Ä‡®Æ‡®æ ‡®¶‡©Ä ‡®∏‡©Ç‡®ö‡©Ä ‡®¨‡®£‡®æ‡®à‡•§ ‡®á‡®π ‡®Ö‡®∏‡©Ä‡®Ç ‡®ú‡®≤‡®¶‡©Ä ‡®ü‡©Ç‡®≤ ‡®®‡©Ç‡©∞ ‡®ï‡®æ‡®≤ ‡®ï‡®∞‡®® ‡®≤‡®à ‡®µ‡®∞‡®§‡®æ‡®Ç‡®ó‡©á‡•§

#### Java

```java
// Create a tool provider that automatically discovers MCP tools
ToolProvider toolProvider = McpToolProvider.builder()
        .mcpClients(List.of(mcpClient))
        .build();

// The MCP tool provider automatically handles:
// - Listing available tools from the MCP server
// - Converting MCP tool schemas to LangChain4j format
// - Managing tool execution and responses
```

‡®â‡®™‡®∞‡©ã‡®ï‡®§ ‡®ï‡©ã‡®° ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç:

- ‡®á‡©±‡®ï `McpToolProvider` ‡®¨‡®£‡®æ‡®á‡®Ü ‡®ú‡©ã MCP ‡®∏‡®∞‡®µ‡®∞ ‡®§‡©ã‡®Ç ‡®∏‡®æ‡®∞‡©á ‡®ü‡©Ç‡®≤ ‡®®‡©Ç‡©∞ ‡®Ü‡®ü‡©ã‡®Æ‡©à‡®ü‡®ø‡®ï ‡®§‡©å‡®∞ '‡®§‡©á ‡®ñ‡©ã‡®ú‡®¶‡®æ ‡®Ö‡®§‡©á ‡®∞‡®ú‡®ø‡®∏‡®ü‡®∞ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§
- ‡®ü‡©Ç‡®≤ ‡®™‡©ç‡®∞‡©ã‡®µ‡®æ‡®à‡®°‡®∞ MCP ‡®ü‡©Ç‡®≤ ‡®∏‡®ï‡©Ä‡®Æ‡®æ‡®Ç ‡®Ö‡®§‡©á LangChain4j ‡®¶‡©á ‡®ü‡©Ç‡®≤ ‡®´‡®æ‡®∞‡®Æ‡©à‡®ü ‡®¶‡©á ‡®µ‡®ø‡®ö‡®ï‡®æ‡®∞ ‡®ï‡®®‡®µ‡®∞‡®ú‡®º‡®® ‡®®‡©Ç‡©∞ ‡®Ö‡©∞‡®¶‡®∞‡©Ç‡®®‡©Ä ‡®§‡©å‡®∞ '‡®§‡©á ‡®∏‡©∞‡®≠‡®æ‡®≤‡®¶‡®æ ‡®π‡©à‡•§
- ‡®á‡®π ‡®™‡®π‡©Å‡©∞‡®ö ‡®Æ‡©à‡®®‡©Ç‡®Ö‡®≤ ‡®ü‡©Ç‡®≤ ‡®∏‡©Ç‡®ö‡©Ä ‡®Ö‡®§‡©á ‡®ï‡®®‡®µ‡®∞‡®ú‡®º‡®® ‡®™‡©ç‡®∞‡®ï‡®ø‡®∞‡®ø‡®Ü ‡®®‡©Ç‡©∞ ‡®Ö‡®¨‡®∏‡®ü‡®∞‡©à‡®ï‡®ü ‡®ï‡®∞‡®¶‡©Ä ‡®π‡©à‡•§

#### Rust

MCP ‡®∏‡®∞‡®µ‡®∞ ‡®§‡©ã‡®Ç ‡®ü‡©Ç‡®≤ ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞‡®®‡®æ `list_tools` ‡®Æ‡©à‡®•‡®° ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®ï‡©Ä‡®§‡®æ ‡®ú‡®æ‡®Ç‡®¶‡®æ ‡®π‡©à‡•§ ‡®Ü‡®™‡®£‡©á `main` ‡®´‡©∞‡®ï‡®∏‡®º‡®® ‡®µ‡®ø‡©±‡®ö, MCP ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®∏‡©à‡®ü ‡®ï‡®∞‡®® ‡®§‡©ã‡®Ç ‡®¨‡®æ‡®Ö‡®¶ ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡®æ ‡®ï‡©ã‡®° ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã:

```rust
// Get MCP tool listing 
let tools = mcp_client.list_tools(Default::default()).await?;
```

### -3- ‡®∏‡®∞‡®µ‡®∞ ‡®¶‡©Ä ‡®∏‡®Æ‡®∞‡©±‡®•‡®æ‡®µ‡®æ‡®Ç ‡®®‡©Ç‡©∞ LLM ‡®ü‡©Ç‡®≤ ‡®µ‡®ø‡©±‡®ö ‡®ï‡®®‡®µ‡®∞‡®ü ‡®ï‡®∞‡©ã

‡®∏‡®∞‡®µ‡®∞ ‡®¶‡©Ä ‡®∏‡®Æ‡®∞‡©±‡®•‡®æ‡®µ‡®æ‡®Ç ‡®¶‡©Ä ‡®∏‡©Ç‡®ö‡©Ä ‡®¨‡®£‡®æ‡®â‡®£ ‡®§‡©ã‡®Ç ‡®¨‡®æ‡®Ö‡®¶ ‡®Ö‡®ó‡®≤‡®æ ‡®ï‡®¶‡®Æ ‡®á‡®π‡®®‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®á‡©±‡®ï ‡®´‡®æ‡®∞‡®Æ‡©à‡®ü ‡®µ‡®ø‡©±‡®ö ‡®ï‡®®‡®µ‡®∞‡®ü ‡®ï‡®∞‡®®‡®æ ‡®π‡©à ‡®ú‡©ã LLM ‡®®‡©Ç‡©∞ ‡®∏‡®Æ‡®ù ‡®Ü‡®â‡®Ç‡®¶‡®æ ‡®π‡©à‡•§ ‡®ú‡®¶‡©ã‡®Ç ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡®π ‡®ï‡®∞ ‡®≤‡©à‡®Ç‡®¶‡©á ‡®π‡®æ‡®Ç, ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡®π ‡®∏‡®Æ‡®∞‡©±‡®•‡®æ‡®µ‡®æ‡®Ç LLM ‡®®‡©Ç‡©∞ ‡®ü‡©Ç‡®≤ ‡®µ‡®ú‡©ã‡®Ç ‡®™‡©ç‡®∞‡®¶‡®æ‡®® ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç‡•§

#### TypeScript

1. MCP Server ‡®§‡©ã‡®Ç ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ú‡®µ‡®æ‡®¨ ‡®®‡©Ç‡©∞ LLM ‡®≤‡®à ‡®µ‡®∞‡®§‡®£‡®Ø‡©ã‡®ó ‡®ü‡©Ç‡®≤ ‡®´‡®æ‡®∞‡®Æ‡©à‡®ü ‡®µ‡®ø‡©±‡®ö ‡®ï‡®®‡®µ‡®∞‡®ü ‡®ï‡®∞‡®® ‡®≤‡®à ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡®æ ‡®ï‡©ã‡®° ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã:

    ```typescript
    openAiToolAdapter(tool: {
        name: string;
        description?: string;
        input_schema: any;
        }) {
        // Create a zod schema based on the input_schema
        const schema = z.object(tool.input_schema);
    
        return {
            type: "function" as const, // Explicitly set type to "function"
            function: {
            name: tool.name,
            description: tool.description,
            parameters: {
            type: "object",
            properties: tool.input_schema.properties,
            required: tool.input_schema.required,
            },
            },
        };
    }

    ```

    ‡®â‡®™‡®∞‡©ã‡®ï‡®§ ‡®ï‡©ã‡®° MCP Server ‡®§‡©ã‡®Ç ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ú‡®µ‡®æ‡®¨ ‡®®‡©Ç‡©∞ LLM ‡®≤‡®à ‡®µ‡®∞‡®§‡®£‡®Ø‡©ã‡®ó ‡®ü‡©Ç‡®≤ ‡®°‡®ø‡®´‡®ø‡®®‡©Ä‡®∏‡®º‡®® ‡®´‡®æ‡®∞‡®Æ‡©à‡®ü ‡®µ‡®ø‡©±‡®ö ‡®ï‡®®‡®µ‡®∞‡®ü ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§

1. ‡®Ü‡®ì `run` ‡®Æ‡©à‡®•‡®° ‡®®‡©Ç‡©∞ ‡®Ö‡®™‡®°‡©á‡®ü ‡®ï‡®∞‡©Ä‡®è:

    ```typescript
    async run() {
        console.log("Asking server for available tools");
        const toolsResult = await this.client.listTools();
        const tools = toolsResult.tools.map((tool) => {
            return this.openAiToolAdapter({
            name: tool.name,
            description: tool.description,
            input_schema: tool.inputSchema,
            });
        });
    }
    ```

    ‡®â‡®™‡®∞‡©ã‡®ï‡®§ ‡®ï‡©ã‡®° ‡®µ‡®ø‡©±‡®ö, ‡®Ö‡®∏‡©Ä‡®Ç `run` ‡®Æ‡©à‡®•‡®° ‡®®‡©Ç‡©∞ ‡®Ö‡®™‡®°‡©á‡®ü ‡®ï‡©Ä‡®§‡®æ ‡®π‡©à ‡®ú‡©ã ‡®®‡®§‡©Ä‡®ú‡©á ‡®¶‡©á ‡®®‡®æ‡®≤ ‡®Æ‡©à‡®™ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à ‡®Ö‡®§‡©á ‡®π‡®∞ ‡®ê‡®Ç‡®ü‡®∞‡©Ä ‡®≤‡®à `openAiToolAdapter` ‡®®‡©Ç‡©∞ ‡®ï‡®æ‡®≤ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§

#### Python

1. ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç, ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡®æ ‡®ï‡®®‡®µ‡®∞‡®ü‡®∞ ‡®´‡©∞‡®ï‡®∏‡®º‡®® ‡®¨‡®£‡®æ‡®ì:

    ```python
    def convert_to_llm_tool(tool):
        tool_schema = {
            "type": "function",
            "function": {
                "name": tool.name,
                "description": tool.description,
                "type": "function",
                "parameters": {
                    "type": "object",
                    "properties": tool.inputSchema["properties"]
                }
            }
        }

        return tool_schema
    ```

    ‡®â‡®™‡®∞‡©ã‡®ï‡®§ ‡®´‡©∞‡®ï‡®∏‡®º‡®® `convert_to_llm_tools` ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç MCP ‡®ü‡©Ç‡®≤ ‡®ú‡®µ‡®æ‡®¨ ‡®®‡©Ç‡©∞ ‡®á‡©±‡®ï ‡®´‡®æ‡®∞‡®Æ‡©à‡®ü ‡®µ‡®ø‡©±‡®ö ‡®ï‡®®‡®µ‡®∞‡®ü ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç ‡®ú‡©ã LLM ‡®®‡©Ç‡©∞ ‡®∏‡®Æ‡®ù ‡®Ü‡®â‡®Ç‡®¶‡®æ ‡®π‡©à‡•§

1. ‡®Ö‡®ó‡®≤‡©á ‡®ï‡®¶‡®Æ ‡®µ‡®ø‡©±‡®ö, ‡®Ü‡®™‡®£‡©á ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®ï‡©ã‡®° ‡®®‡©Ç‡©∞ ‡®á‡®∏ ‡®´‡©∞‡®ï‡®∏‡®º‡®® ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®® ‡®≤‡®à ‡®Ö‡®™‡®°‡©á‡®ü ‡®ï‡®∞‡©ã:

    ```python
    for tool in tools.tools:
        print("Tool: ", tool.name)
        print("Tool", tool.inputSchema["properties"])
        functions.append(convert_to_llm_tool(tool))
    ```

    ‡®á‡©±‡®•‡©á, ‡®Ö‡®∏‡©Ä‡®Ç MCP ‡®ü‡©Ç‡®≤ ‡®ú‡®µ‡®æ‡®¨ ‡®®‡©Ç‡©∞ ‡®¨‡®æ‡®Ö‡®¶ ‡®µ‡®ø‡©±‡®ö LLM ‡®®‡©Ç‡©∞ ‡®´‡©Ä‡®° ‡®ï‡®∞‡®® ‡®≤‡®à ‡®ï‡®®‡®µ‡®∞‡®ü ‡®ï‡®∞‡®® ‡®≤‡®à `convert_to_llm_tool` ‡®®‡©Ç‡©∞ ‡®ï‡®æ‡®≤ ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç‡•§

#### .NET

1. ‡®Ü‡®ì MCP ‡®ü‡©Ç‡®≤ ‡®ú‡®µ‡®æ‡®¨ ‡®®‡©Ç‡©∞ LLM ‡®≤‡®à ‡®µ‡®∞‡®§‡®£‡®Ø‡©ã‡®ó ‡®´‡®æ‡®∞‡®Æ‡©à‡®ü ‡®µ‡®ø‡©±‡®ö ‡®ï‡®®‡®µ‡®∞‡®ü ‡®ï‡®∞‡®® ‡®≤‡®à ‡®ï‡©ã‡®° ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©Ä‡®è:

```csharp
ChatCompletionsToolDefinition ConvertFrom(string name, string description, JsonElement jsonElement)
{ 
    // convert the tool to a function definition
    FunctionDefinition functionDefinition = new FunctionDefinition(name)
    {
        Description = description,
        Parameters = BinaryData.FromObjectAsJson(new
        {
            Type = "object",
            Properties = jsonElement
        },
        new JsonSerializerOptions() { PropertyNamingPolicy = JsonNamingPolicy.CamelCase })
    };

    // create a tool definition
    ChatCompletionsToolDefinition toolDefinition = new ChatCompletionsToolDefinition(functionDefinition);
    return toolDefinition;
}
```

‡®â‡®™‡®∞‡©ã‡®ï‡®§ ‡®ï‡©ã‡®° ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç:

- ‡®á‡©±‡®ï ‡®´‡©∞‡®ï‡®∏‡®º‡®® `ConvertFrom` ‡®¨‡®£‡®æ‡®á‡®Ü ‡®ú‡©ã ‡®®‡®æ‡®Æ, ‡®µ‡©á‡®∞‡®µ‡®æ ‡®Ö‡®§‡©á ‡®á‡©∞‡®™‡©Å‡®ü ‡®∏‡®ï‡©Ä‡®Æ‡®æ ‡®≤‡©à‡®Ç‡®¶‡®æ ‡®π‡©à‡•§
- FunctionDefinition ‡®¨‡®£‡®æ‡®â‡®£ ‡®¶‡©Ä ‡®µ‡®ø‡®µ‡®∏‡®•‡®æ ‡®®‡©Ç‡©∞ ‡®™‡®∞‡®ø‡®≠‡®æ‡®∏‡®º‡®ø‡®§ ‡®ï‡©Ä‡®§‡®æ ‡®ú‡©ã ChatCompletionsDefinition ‡®®‡©Ç‡©∞ ‡®™‡®æ‡®∏ ‡®ï‡©Ä‡®§‡®æ ‡®ú‡®æ‡®Ç‡®¶‡®æ ‡®π‡©à‡•§ ‡®á‡®π LLM ‡®®‡©Ç‡©∞ ‡®∏‡®Æ‡®ù ‡®Ü‡®â‡®Ç‡®¶‡®æ ‡®π‡©à‡•§

1. ‡®Ü‡®ì ‡®ï‡©Å‡®ù ‡®Æ‡©å‡®ú‡©Ç‡®¶‡®æ ‡®ï‡©ã‡®° ‡®®‡©Ç‡©∞ ‡®Ö‡®™‡®°‡©á‡®ü ‡®ï‡®∞‡®® ‡®¶‡©á ‡®§‡®∞‡©Ä‡®ï‡©á ‡®¶‡©á‡®ñ‡©Ä‡®è:

    ```csharp
    async Task<List<ChatCompletionsToolDefinition>> GetMcpTools()
    {
        Console.WriteLine("Listing tools");
        var tools = await mcpClient.ListToolsAsync();

        List<ChatCompletionsToolDefinition> toolDefinitions = new List<ChatCompletionsToolDefinition>();

        foreach (var tool in tools)
        {
            Console.WriteLine($"Connected to server with tools: {tool.Name}");
            Console.WriteLine($"Tool description: {tool.Description}");
            Console.WriteLine($"Tool parameters: {tool.JsonSchema}");

            JsonElement propertiesElement;
            tool.JsonSchema.TryGetProperty("properties", out propertiesElement);

            var def = ConvertFrom(tool.Name, tool.Description, propertiesElement);
            Console.WriteLine($"Tool definition: {def}");
            toolDefinitions.Add(def);

            Console.WriteLine($"Properties: {propertiesElement}");        
        }

        return toolDefinitions;
    }
    ```    In the preceding code, we've:

    - Update the function to convert the MCP tool response to an LLm tool. Let's highlight the code we added:

        ```csharp
        JsonElement propertiesElement;
        tool.JsonSchema.TryGetProperty("properties", out propertiesElement);

        var def = ConvertFrom(tool.Name, tool.Description, propertiesElement);
        Console.WriteLine($"Tool definition: {def}");
        toolDefinitions.Add(def);
        ```

        The input schema is part of the tool response but on the "properties" attribute, so we need to extract. Furthermore, we now call `ConvertFrom` with the tool details. Now we've done the heavy lifting, let's see how it call comes together as we handle a user prompt next.

#### Java

```java
// Create a Bot interface for natural language interaction
public interface Bot {
    String chat(String prompt);
}

// Configure the AI service with LLM and MCP tools
Bot bot = AiServices.builder(Bot.class)
        .chatLanguageModel(model)
        .toolProvider(toolProvider)
        .build();
```

‡®â‡®™‡®∞‡©ã‡®ï‡®§ ‡®ï‡©ã‡®° ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç:

- ‡®ï‡©Å‡®¶‡®∞‡®§‡©Ä ‡®≠‡®æ‡®∏‡®º‡®æ ‡®∏‡©∞‡®ö‡®æ‡®∞ ‡®≤‡®à ‡®á‡©±‡®ï ‡®∏‡®ß‡®æ‡®∞‡®® `Bot` ‡®á‡©∞‡®ü‡®∞‡®´‡©á‡®∏ ‡®™‡®∞‡®ø‡®≠‡®æ‡®∏‡®º‡®ø‡®§ ‡®ï‡©Ä‡®§‡®æ‡•§
- LangChain4j ‡®¶‡©á `AiServices` ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡©Ä‡®§‡©Ä ‡®ú‡©ã LLM ‡®®‡©Ç‡©∞ MCP ‡®ü‡©Ç‡®≤ ‡®™‡©ç‡®∞‡©ã‡®µ‡®æ‡®à‡®°‡®∞ ‡®®‡®æ‡®≤ ‡®Ü‡®ü‡©ã‡®Æ‡©à‡®ü‡®ø‡®ï ‡®§‡©å‡®∞ '‡®§‡©á ‡®¨‡®æ‡®à‡®Ç‡®° ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§
- ‡®´‡®∞‡©á‡®Æ‡®µ‡®∞‡®ï ‡®Ü‡®ü‡©ã‡®Æ‡©à‡®ü‡®ø‡®ï ‡®§‡©å‡®∞ '‡®§‡©á ‡®ü‡©Ç‡®≤ ‡®∏‡®ï‡©Ä‡®Æ‡®æ ‡®ï‡®®‡®µ‡®∞‡®ú‡®º‡®® ‡®Ö‡®§‡©á ‡®´‡©∞‡®ï‡®∏‡®º‡®® ‡®ï‡®æ‡®≤‡®ø‡©∞‡®ó ‡®®‡©Ç‡©∞ ‡®∏‡©∞‡®≠‡®æ‡®≤‡®¶‡®æ ‡®π‡©à‡•§
- ‡®á‡®π ‡®™‡®π‡©Å‡©∞‡®ö ‡®Æ‡©à‡®®‡©Ç‡®Ö‡®≤ ‡®ü‡©Ç‡®≤ ‡®ï‡®®‡®µ‡®∞‡®ú‡®º‡®® ‡®®‡©Ç‡©∞ ‡®π‡®ü‡®æ‡®â‡®Ç‡®¶‡©Ä ‡®π‡©à - LangChain4j MCP ‡®ü‡©Ç‡®≤ ‡®®‡©Ç‡©∞ LLM-‡®ï‡©∞‡®™‡©à‡®ü‡®ø‡®¨‡®≤ ‡®´‡®æ‡®∞‡®Æ‡©à‡®ü ‡®µ‡®ø‡©±‡®ö ‡®ï‡®®‡®µ‡®∞‡®ü ‡®ï‡®∞‡®® ‡®¶‡©Ä ‡®∏‡®æ‡®∞‡©Ä ‡®ú‡®ü‡®ø‡®≤‡®§‡®æ ‡®®‡©Ç‡©∞ ‡®∏‡©∞‡®≠‡®æ‡®≤‡®¶‡®æ ‡®π‡©à‡•§

#### Rust

MCP ‡®ü‡©Ç‡®≤ ‡®ú‡®µ‡®æ‡®¨ ‡®®‡©Ç‡©∞ ‡®á‡©±‡®ï ‡®´‡®æ‡®∞‡®Æ‡©à‡®ü ‡®µ‡®ø‡©±‡®ö ‡®ï‡®®‡®µ‡®∞‡®ü ‡®ï‡®∞‡®® ‡®≤‡®à ‡®ú‡©ã LLM ‡®®‡©Ç‡©∞ ‡®∏‡®Æ‡®ù ‡®Ü‡®â‡®Ç‡®¶‡®æ ‡®π‡©à, ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡©±‡®ï ‡®π‡©á‡®≤‡®™‡®∞ ‡®´‡©∞‡®ï‡®∏‡®º‡®® ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡®æ‡®Ç‡®ó‡©á ‡®ú‡©ã ‡®ü‡©Ç‡®≤ ‡®∏‡©Ç‡®ö‡©Ä‡®¨‡©±‡®ß ‡®ï‡®∞‡®® ‡®¶‡©Ä ‡®µ‡®ø‡®µ‡®∏‡®•‡®æ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§ ‡®Ü‡®™‡®£‡©á `main.rs` ‡®´‡®æ‡®à‡®≤ ‡®µ‡®ø‡©±‡®ö ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡®æ ‡®ï‡©ã‡®° ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã:

```rust
async fn format_tools(tools: &ListToolsResult) -> Result<Vec<Value>, Box<dyn Error>> {
    let tools_json = serde_json::to_value(tools)?;
    let Some(tools_array) = tools_json.get("tools").and_then(|t| t.as_array()) else {
        return Ok(vec![]);
    };

    let formatted_tools = tools_array
        .iter()
        .filter_map(|tool| {
            let name = tool.get("name")?.as_str()?;
            let description = tool.get("description")?.as_str()?;
            let schema = tool.get("inputSchema")?;

            Some(json!({
                "type": "function",
                "function": {
                    "name": name,
                    "description": description,
                    "parameters": {
                        "type": "object",
                        "properties": schema.get("properties").unwrap_or(&json!({})),
                        "required": schema.get("required").unwrap_or(&json!([]))
                    }
                }
            }))
        })
        .collect();

    Ok(formatted_tools)
}
```

‡®µ‡®ß‡©Ä‡®Ü, ‡®Ö‡®∏‡©Ä‡®Ç ‡®π‡©Å‡®£ ‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®Ø‡©Ç‡®ú‡®º‡®∞ ‡®¶‡©Ä ‡®¨‡©á‡®®‡®§‡©Ä ‡®®‡©Ç‡©∞ ‡®∏‡©∞‡®≠‡®æ‡®≤‡®£ ‡®≤‡®à ‡®∏‡©à‡®ü ‡®π‡©ã ‡®ó‡®è ‡®π‡®æ‡®Ç, ‡®§‡®æ‡®Ç ‡®Ü‡®ì ‡®Ö‡®ó‡®≤‡©á ‡®ï‡®¶‡®Æ ‡®µ‡®ø‡©±‡®ö ‡®á‡®∏‡®®‡©Ç‡©∞ ‡®π‡©±‡®≤ ‡®ï‡®∞‡©Ä‡®è‡•§

### -4- ‡®Ø‡©Ç‡®ú‡®º‡®∞ ‡®™‡©ç‡®∞‡©ã‡©∞‡®™‡®ü ‡®¨‡©á‡®®‡®§‡©Ä ‡®®‡©Ç‡©∞ ‡®∏‡©∞‡®≠‡®æ‡®≤‡©ã

‡®á‡®∏ ‡®ï‡©ã‡®° ‡®¶‡©á ‡®π‡®ø‡©±‡®∏‡©á ‡®µ‡®ø‡©±‡®ö, ‡®Ö‡®∏‡©Ä‡®Ç ‡®Ø‡©Ç‡®ú‡®º‡®∞ ‡®¶‡©Ä‡®Ü‡®Ç ‡®¨‡©á‡®®‡®§‡©Ä‡®Ü‡®Ç ‡®®‡©Ç‡©∞ ‡®∏‡©∞‡®≠‡®æ‡®≤‡®æ‡®Ç‡®ó‡©á‡•§

#### TypeScript

1. ‡®á‡©±‡®ï ‡®Æ‡©à‡®•‡®° ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã ‡®ú‡©ã ‡®∏‡®æ‡®°‡©á LLM ‡®®‡©Ç‡©∞ ‡®ï‡®æ‡®≤ ‡®ï‡®∞‡®® ‡®≤‡®à ‡®µ‡®∞‡®§‡®ø‡®Ü ‡®ú‡®æ‡®µ‡©á‡®ó‡®æ:

    ```typescript
    async callTools(
        tool_calls: OpenAI.Chat.Completions.ChatCompletionMessageToolCall[],
        toolResults: any[]
    ) {
        for (const tool_call of tool_calls) {
        const toolName = tool_call.function.name;
        const args = tool_call.function.arguments;

        console.log(`Calling tool ${toolName} with args ${JSON.stringify(args)}`);


        // 2. Call the server's tool 
        const toolResult = await this.client.callTool({
            name: toolName,
            arguments: JSON.parse(args),
        });

        console.log("Tool result: ", toolResult);

        // 3. Do something with the result
        // TODO  

        }
    }
    ```

    ‡®â‡®™‡®∞‡©ã‡®ï‡®§ ‡®ï‡©ã‡®° ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç:

    - ‡®á‡©±‡®ï ‡®Æ‡©à‡®•‡®° `callTools` ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡©Ä‡®§‡®æ‡•§
    - ‡®Æ‡©à‡®•‡®° LLM ‡®ú‡®µ‡®æ‡®¨ ‡®≤‡©à‡®Ç‡®¶‡®æ ‡®π‡©à ‡®Ö‡®§‡©á ‡®ú‡®æ‡®Ç‡®ö‡®¶‡®æ ‡®π‡©à ‡®ï‡®ø ‡®ï‡©Ä ‡®ï‡©ã‡®à ‡®ü‡©Ç‡®≤ ‡®ï‡®æ‡®≤ ‡®ï‡©Ä‡®§‡©á ‡®ó‡®è ‡®π‡®®:

        ```typescript
        for (const tool_call of tool_calls) {
        const toolName = tool_call.function.name;
        const args = tool_call.function.arguments;

        console.log(`Calling tool ${toolName} with args ${JSON.stringify(args)}`);

        // call tool
        }
        ```

    - ‡®ú‡©á LLM ‡®∏‡©∞‡®ï‡©á‡®§ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à ‡®§‡®æ‡®Ç ‡®ü‡©Ç‡®≤ ‡®®‡©Ç‡©∞ ‡®ï‡®æ‡®≤ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à:

        ```typescript
        // 2. Call the server's tool 
        const toolResult = await this.client.callTool({
            name: toolName,
            arguments: JSON.parse(args),
        });

        console.log("Tool result: ", toolResult);

        // 3. Do something with the result
        // TODO  
        ```

1. `run` ‡®Æ‡©à‡®•‡®° ‡®®‡©Ç‡©∞ ‡®Ö‡®™‡®°‡©á‡®ü ‡®ï‡®∞‡©ã:

    ```typescript

    // 1. Create messages that's input for the LLM
    const prompt = "What is the sum of 2 and 3?"

    const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
            {
                role: "user",
                content: prompt,
            },
        ];

    console.log("Querying LLM: ", messages[0].content);

    // 2. Calling the LLM
    let response = this.openai.chat.completions.create({
        model: "gpt-4o-mini",
        max_tokens: 1000,
        messages,
        tools: tools,
    });    

    let results: any[] = [];

    // 3. Go through the LLM response,for each choice, check if it has tool calls 
    (await response).choices.map(async (choice: { message: any; }) => {
        const message = choice.message;
        if (message.tool_calls) {
            console.log("Making tool call")
            await this.callTools(message.tool_calls, results);
        }
    });
    ```

‡®µ‡®ß‡©Ä‡®Ü, ‡®Ü‡®ì ‡®™‡©Ç‡®∞‡©á ‡®ï‡©ã‡®° ‡®®‡©Ç‡©∞ ‡®∏‡©Ç‡®ö‡©Ä‡®¨‡©±‡®ß ‡®ï‡®∞‡©Ä‡®è:

```typescript
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import { Transport } from "@modelcontextprotocol/sdk/shared/transport.js";
import OpenAI from "openai";
import { z } from "zod"; // Import zod for schema validation

class MyClient {
    private openai: OpenAI;
    private client: Client;
    constructor(){
        this.openai = new OpenAI({
            baseURL: "https://models.inference.ai.azure.com", // might need to change to this url in the future: https://models.github.ai/inference
            apiKey: process.env.GITHUB_TOKEN,
        });

        this.client = new Client(
            {
                name: "example-client",
                version: "1.0.0"
            },
            {
                capabilities: {
                prompts: {},
                resources: {},
                tools: {}
                }
            }
            );    
    }

    async connectToServer(transport: Transport) {
        await this.client.connect(transport);
        this.run();
        console.error("MCPClient started on stdin/stdout");
    }

    openAiToolAdapter(tool: {
        name: string;
        description?: string;
        input_schema: any;
          }) {
          // Create a zod schema based on the input_schema
          const schema = z.object(tool.input_schema);
      
          return {
            type: "function" as const, // Explicitly set type to "function"
            function: {
              name: tool.name,
              description: tool.description,
              parameters: {
              type: "object",
              properties: tool.input_schema.properties,
              required: tool.input_schema.required,
              },
            },
          };
    }
    
    async callTools(
        tool_calls: OpenAI.Chat.Completions.ChatCompletionMessageToolCall[],
        toolResults: any[]
      ) {
        for (const tool_call of tool_calls) {
          const toolName = tool_call.function.name;
          const args = tool_call.function.arguments;
    
          console.log(`Calling tool ${toolName} with args ${JSON.stringify(args)}`);
    
    
          // 2. Call the server's tool 
          const toolResult = await this.client.callTool({
            name: toolName,
            arguments: JSON.parse(args),
          });
    
          console.log("Tool result: ", toolResult);
    
          // 3. Do something with the result
          // TODO  
    
         }
    }

    async run() {
        console.log("Asking server for available tools");
        const toolsResult = await this.client.listTools();
        const tools = toolsResult.tools.map((tool) => {
            return this.openAiToolAdapter({
              name: tool.name,
              description: tool.description,
              input_schema: tool.inputSchema,
            });
        });

        const prompt = "What is the sum of 2 and 3?";
    
        const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
            {
                role: "user",
                content: prompt,
            },
        ];

        console.log("Querying LLM: ", messages[0].content);
        let response = this.openai.chat.completions.create({
            model: "gpt-4o-mini",
            max_tokens: 1000,
            messages,
            tools: tools,
        });    

        let results: any[] = [];
    
        // 1. Go through the LLM response,for each choice, check if it has tool calls 
        (await response).choices.map(async (choice: { message: any; }) => {
          const message = choice.message;
          if (message.tool_calls) {
              console.log("Making tool call")
              await this.callTools(message.tool_calls, results);
          }
        });
    }
    
}

let client = new MyClient();
 const transport = new StdioClientTransport({
            command: "node",
            args: ["./build/index.js"]
        });

client.connectToServer(transport);
```

#### Python

1. ‡®Ü‡®ì ‡®ï‡©Å‡®ù ‡®á‡©∞‡®™‡©ã‡®∞‡®ü ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©Ä‡®è ‡®ú‡©ã LLM ‡®®‡©Ç‡©∞ ‡®ï‡®æ‡®≤ ‡®ï‡®∞‡®® ‡®≤‡®à ‡®≤‡©ã
LLM ‡®¶‡©á ‡®ú‡®µ‡®æ‡®¨ ‡®µ‡®ø‡©±‡®ö `choices` ‡®¶‡©Ä ‡®á‡©±‡®ï ‡®ê‡®∞‡©á ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®π‡©ã‡®µ‡©á‡®ó‡©Ä‡•§ ‡®∏‡®æ‡®®‡©Ç‡©∞ ‡®®‡®§‡©Ä‡®ú‡©á ‡®®‡©Ç‡©∞ ‡®™‡©ç‡®∞‡©ã‡®∏‡©à‡®∏ ‡®ï‡®∞‡®®‡®æ ‡®™‡®µ‡©á‡®ó‡®æ ‡®§‡®æ‡®Ç ‡®ú‡©ã ‡®¶‡©á‡®ñ‡®ø‡®Ü ‡®ú‡®æ ‡®∏‡®ï‡©á ‡®ï‡®ø ‡®ï‡©ã‡®à `tool_calls` ‡®Æ‡©å‡®ú‡©Ç‡®¶ ‡®π‡®® ‡®ú‡®æ‡®Ç ‡®®‡®π‡©Ä‡®Ç‡•§ ‡®á‡®π ‡®∏‡®æ‡®®‡©Ç‡©∞ ‡®¶‡©±‡®∏‡®¶‡®æ ‡®π‡©à ‡®ï‡®ø LLM ‡®á‡©±‡®ï ‡®ñ‡®æ‡®∏ ‡®ü‡©Ç‡®≤ ‡®®‡©Ç‡©∞ ‡®¶‡®≤‡©Ä‡®≤‡®æ‡®Ç ‡®®‡®æ‡®≤ ‡®ï‡®æ‡®≤ ‡®ï‡®∞‡®® ‡®¶‡©Ä ‡®¨‡©á‡®®‡®§‡©Ä ‡®ï‡®∞ ‡®∞‡®ø‡®π‡®æ ‡®π‡©à‡•§ ‡®Ü‡®™‡®£‡©á `main.rs` ‡®´‡®æ‡®à‡®≤ ‡®¶‡©á ‡®Ö‡©∞‡®§ ‡®µ‡®ø‡©±‡®ö ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡®æ ‡®ï‡©ã‡®° ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã ‡®§‡®æ‡®Ç ‡®ú‡©ã LLM ‡®¶‡©á ‡®ú‡®µ‡®æ‡®¨ ‡®®‡©Ç‡©∞ ‡®∏‡©∞‡®≠‡®æ‡®≤‡®£ ‡®≤‡®à ‡®á‡©±‡®ï ‡®´‡©∞‡®ï‡®∏‡®º‡®® ‡®™‡®∞‡®ø‡®≠‡®æ‡®∏‡®º‡®ø‡®§ ‡®ï‡©Ä‡®§‡®æ ‡®ú‡®æ ‡®∏‡®ï‡©á:

```rust
async fn process_llm_response(
    llm_response: &Value,
    mcp_client: &RunningService<RoleClient, ()>,
    openai_client: &Client<OpenAIConfig>,
    mcp_tools: &ListToolsResult,
    messages: &mut Vec<Value>,
) -> Result<(), Box<dyn Error>> {
    let Some(message) = llm_response
        .get("choices")
        .and_then(|c| c.as_array())
        .and_then(|choices| choices.first())
        .and_then(|choice| choice.get("message"))
    else {
        return Ok(());
    };

    // Print content if available
    if let Some(content) = message.get("content").and_then(|c| c.as_str()) {
        println!("ü§ñ {}", content);
    }

    // Handle tool calls
    if let Some(tool_calls) = message.get("tool_calls").and_then(|tc| tc.as_array()) {
        messages.push(message.clone()); // Add assistant message

        // Execute each tool call
        for tool_call in tool_calls {
            let (tool_id, name, args) = extract_tool_call_info(tool_call)?;
            println!("‚ö° Calling tool: {}", name);

            let result = mcp_client
                .call_tool(CallToolRequestParam {
                    name: name.into(),
                    arguments: serde_json::from_str::<Value>(&args)?.as_object().cloned(),
                })
                .await?;

            // Add tool result to messages
            messages.push(json!({
                "role": "tool",
                "tool_call_id": tool_id,
                "content": serde_json::to_string_pretty(&result)?
            }));
        }

        // Continue conversation with tool results
        let response = call_llm(openai_client, messages, mcp_tools).await?;
        Box::pin(process_llm_response(
            &response,
            mcp_client,
            openai_client,
            mcp_tools,
            messages,
        ))
        .await?;
    }
    Ok(())
}
```

‡®ú‡©á `tool_calls` ‡®Æ‡©å‡®ú‡©Ç‡®¶ ‡®π‡®®, ‡®§‡®æ‡®Ç ‡®á‡®π ‡®ü‡©Ç‡®≤ ‡®¶‡©Ä ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®®‡®ø‡®ï‡®æ‡®≤‡®¶‡®æ ‡®π‡©à, ‡®ü‡©Ç‡®≤ ‡®¨‡©á‡®®‡®§‡©Ä ‡®®‡®æ‡®≤ MCP ‡®∏‡®∞‡®µ‡®∞ ‡®®‡©Ç‡©∞ ‡®ï‡®æ‡®≤ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à, ‡®Ö‡®§‡©á ‡®®‡®§‡©Ä‡®ú‡®ø‡®Ü‡®Ç ‡®®‡©Ç‡©∞ ‡®ó‡©±‡®≤‡®¨‡®æ‡®§ ‡®¶‡©á ‡®∏‡©Å‡®®‡©á‡®π‡®ø‡®Ü‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§ ‡®á‡®π ‡®´‡®ø‡®∞ LLM ‡®®‡®æ‡®≤ ‡®ó‡©±‡®≤‡®¨‡®æ‡®§ ‡®ú‡®æ‡®∞‡©Ä ‡®∞‡©±‡®ñ‡®¶‡®æ ‡®π‡©à ‡®Ö‡®§‡©á ‡®∏‡©Å‡®®‡©á‡®π‡©á ‡®∏‡®π‡®æ‡®á‡®ï ‡®¶‡©á ‡®ú‡®µ‡®æ‡®¨ ‡®Ö‡®§‡©á ‡®ü‡©Ç‡®≤ ‡®ï‡®æ‡®≤ ‡®®‡®§‡©Ä‡®ú‡®ø‡®Ü‡®Ç ‡®®‡®æ‡®≤ ‡®Ö‡®™‡®°‡©á‡®ü ‡®ï‡©Ä‡®§‡©á ‡®ú‡®æ‡®Ç‡®¶‡©á ‡®π‡®®‡•§

MCP ‡®ï‡®æ‡®≤‡®æ‡®Ç ‡®≤‡®à LLM ‡®µ‡©±‡®≤‡©ã‡®Ç ‡®µ‡®æ‡®™‡®∏ ‡®ï‡©Ä‡®§‡©á ‡®ü‡©Ç‡®≤ ‡®ï‡®æ‡®≤ ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®®‡©Ç‡©∞ ‡®®‡®ø‡®ï‡®æ‡®≤‡®£ ‡®≤‡®à, ‡®∏‡®æ‡®®‡©Ç‡©∞ ‡®á‡©±‡®ï ‡®π‡©ã‡®∞ ‡®π‡©á‡®≤‡®™‡®∞ ‡®´‡©∞‡®ï‡®∏‡®º‡®® ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡®®‡®æ ‡®™‡®µ‡©á‡®ó‡®æ ‡®ú‡©ã ‡®ï‡®æ‡®≤ ‡®ï‡®∞‡®® ‡®≤‡®à ‡®≤‡©ã‡©ú‡©Ä‡®Ç‡®¶‡®æ ‡®∏‡®≠ ‡®ï‡©Å‡®ù ‡®®‡®ø‡®ï‡®æ‡®≤‡©á‡•§ ‡®Ü‡®™‡®£‡©á `main.rs` ‡®´‡®æ‡®à‡®≤ ‡®¶‡©á ‡®Ö‡©∞‡®§ ‡®µ‡®ø‡©±‡®ö ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡®æ ‡®ï‡©ã‡®° ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã:

```rust
fn extract_tool_call_info(tool_call: &Value) -> Result<(String, String, String), Box<dyn Error>> {
    let tool_id = tool_call
        .get("id")
        .and_then(|id| id.as_str())
        .unwrap_or("")
        .to_string();
    let function = tool_call.get("function").ok_or("Missing function")?;
    let name = function
        .get("name")
        .and_then(|n| n.as_str())
        .unwrap_or("")
        .to_string();
    let args = function
        .get("arguments")
        .and_then(|a| a.as_str())
        .unwrap_or("{}")
        .to_string();
    Ok((tool_id, name, args))
}
```

‡®∏‡®æ‡®∞‡©á ‡®π‡®ø‡©±‡®∏‡©á ‡®∏‡®•‡®æ‡®™‡®ø‡®§ ‡®π‡©ã‡®£ ‡®¶‡©á ‡®®‡®æ‡®≤, ‡®π‡©Å‡®£ ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®º‡©Å‡®∞‡©Ç‡®Ü‡®§‡©Ä ‡®Ø‡©Ç‡®ú‡®º‡®∞ ‡®™‡©ç‡®∞‡®æ‡®Ç‡®™‡®ü ‡®®‡©Ç‡©∞ ‡®∏‡©∞‡®≠‡®æ‡®≤ ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç ‡®Ö‡®§‡©á LLM ‡®®‡©Ç‡©∞ ‡®ï‡®æ‡®≤ ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç‡•§ ‡®Ü‡®™‡®£‡©á `main` ‡®´‡©∞‡®ï‡®∏‡®º‡®® ‡®®‡©Ç‡©∞ ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡©á ‡®ï‡©ã‡®° ‡®®‡®æ‡®≤ ‡®Ö‡®™‡®°‡©á‡®ü ‡®ï‡®∞‡©ã:

```rust
// LLM conversation with tool calls
let response = call_llm(&openai_client, &messages, &tools).await?;
process_llm_response(
    &response,
    &mcp_client,
    &openai_client,
    &tools,
    &mut messages,
)
.await?;
```

‡®á‡®π LLM ‡®®‡©Ç‡©∞ ‡®∏‡®º‡©Å‡®∞‡©Ç‡®Ü‡®§‡©Ä ‡®Ø‡©Ç‡®ú‡®º‡®∞ ‡®™‡©ç‡®∞‡®æ‡®Ç‡®™‡®ü ‡®¶‡©á ‡®®‡®æ‡®≤ ‡®™‡©Å‡©±‡®õ‡©á‡®ó‡®æ ‡®ï‡®ø ‡®¶‡©ã ‡®®‡©∞‡®¨‡®∞‡®æ‡®Ç ‡®¶‡®æ ‡®ú‡©ã‡©ú ‡®ï‡©Ä ‡®π‡©à, ‡®Ö‡®§‡©á ‡®ú‡®µ‡®æ‡®¨ ‡®®‡©Ç‡©∞ ‡®™‡©ç‡®∞‡©ã‡®∏‡©à‡®∏ ‡®ï‡®∞‡©á‡®ó‡®æ ‡®§‡®æ‡®Ç ‡®ú‡©ã ‡®ü‡©Ç‡®≤ ‡®ï‡®æ‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®ó‡®§‡©Ä‡®∏‡®º‡©Ä‡®≤ ‡®§‡®∞‡©Ä‡®ï‡©á ‡®®‡®æ‡®≤ ‡®∏‡©∞‡®≠‡®æ‡®≤‡®ø‡®Ü ‡®ú‡®æ ‡®∏‡®ï‡©á‡•§

‡®µ‡®ß‡©Ä‡®Ü, ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®ï‡®∞ ‡®≤‡®ø‡®Ü!

## ‡®Ö‡®∏‡®æ‡®à‡®®‡®Æ‡©à‡®Ç‡®ü

‡®Ö‡®≠‡®ø‡®Ü‡®∏ ‡®µ‡®ø‡©±‡®ö ‡®¶‡®ø‡©±‡®§‡©á ‡®ï‡©ã‡®° ‡®®‡©Ç‡©∞ ‡®≤‡®ì ‡®Ö‡®§‡©á ‡®∏‡®∞‡®µ‡®∞ ‡®µ‡®ø‡©±‡®ö ‡®ï‡©Å‡®ù ‡®π‡©ã‡®∞ ‡®ü‡©Ç‡®≤ ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã‡•§ ‡®´‡®ø‡®∞ ‡®á‡©±‡®ï LLM ‡®¶‡©á ‡®®‡®æ‡®≤ ‡®á‡©±‡®ï ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®¨‡®£‡®æ‡®ì, ‡®ú‡®ø‡®µ‡©á‡®Ç ‡®ï‡®ø ‡®Ö‡®≠‡®ø‡®Ü‡®∏ ‡®µ‡®ø‡©±‡®ö, ‡®Ö‡®§‡©á ‡®µ‡©±‡®ñ-‡®µ‡©±‡®ñ ‡®™‡©ç‡®∞‡®æ‡®Ç‡®™‡®ü‡®æ‡®Ç ‡®®‡®æ‡®≤ ‡®á‡®∏‡®®‡©Ç‡©∞ ‡®ü‡©à‡®∏‡®ü ‡®ï‡®∞‡©ã ‡®§‡®æ‡®Ç ‡®ï‡®ø ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®∏‡®∞‡®µ‡®∞ ‡®ü‡©Ç‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®ó‡®§‡©Ä‡®∏‡®º‡©Ä‡®≤ ‡®§‡®∞‡©Ä‡®ï‡©á ‡®®‡®æ‡®≤ ‡®ï‡®æ‡®≤ ‡®ï‡©Ä‡®§‡®æ ‡®ú‡®æ ‡®∏‡®ï‡©á‡•§ ‡®á‡®∏ ‡®§‡®∞‡©Ä‡®ï‡©á ‡®®‡®æ‡®≤ ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®¨‡®£‡®æ‡®â‡®£ ‡®¶‡®æ ‡®Æ‡®§‡®≤‡®¨ ‡®π‡©à ‡®ï‡®ø ‡®Ö‡©∞‡®§‡®Æ ‡®Ø‡©Ç‡®ú‡®º‡®∞ ‡®®‡©Ç‡©∞ ‡®¨‡®π‡©Å‡®§ ‡®µ‡®ß‡©Ä‡®Ü ‡®Ö‡®®‡©Å‡®≠‡®µ ‡®Æ‡®ø‡®≤‡©á‡®ó‡®æ ‡®ï‡®ø‡®â‡®Ç‡®ï‡®ø ‡®â‡®π ‡®™‡©ç‡®∞‡®æ‡®Ç‡®™‡®ü‡®æ‡®Ç ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®® ‡®¶‡©á ‡®Ø‡©ã‡®ó ‡®π‡©ã‡®£‡®ó‡©á, ‡®∏‡®π‡©Ä ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®ï‡®Æ‡®æ‡®Ç‡®°‡®æ‡®Ç ‡®¶‡©Ä ‡®¨‡®ú‡®æ‡®è, ‡®Ö‡®§‡©á ‡®ï‡®ø‡®∏‡©á MCP ‡®∏‡®∞‡®µ‡®∞ ‡®¶‡©á ‡®ï‡®æ‡®≤ ‡®π‡©ã‡®£ ‡®§‡©ã‡®Ç ‡®¨‡©á‡®ñ‡®º‡®¨‡®∞ ‡®∞‡®π‡®ø‡®£‡®ó‡©á‡•§

## ‡®π‡©±‡®≤

[Solution](/03-GettingStarted/03-llm-client/solution/README.md)

## ‡®Æ‡©Å‡©±‡®ñ ‡®∏‡®ø‡©±‡®ñ‡®ø‡®Ü

- ‡®Ü‡®™‡®£‡©á ‡®ï‡®≤‡®æ‡®á‡©∞‡®ü ‡®µ‡®ø‡©±‡®ö LLM ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡®®‡®æ ‡®Ø‡©Ç‡®ú‡®º‡®∞‡®æ‡®Ç ‡®®‡©Ç‡©∞ MCP ‡®∏‡®∞‡®µ‡®∞‡®æ‡®Ç ‡®®‡®æ‡®≤ ‡®∏‡©∞‡®ö‡®æ‡®∞ ‡®ï‡®∞‡®® ‡®¶‡®æ ‡®á‡©±‡®ï ‡®µ‡®ß‡©Ä‡®Ü ‡®§‡®∞‡©Ä‡®ï‡®æ ‡®™‡©ç‡®∞‡®¶‡®æ‡®® ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§
- ‡®§‡©Å‡®π‡®æ‡®®‡©Ç‡©∞ MCP ‡®∏‡®∞‡®µ‡®∞ ‡®¶‡©á ‡®ú‡®µ‡®æ‡®¨ ‡®®‡©Ç‡©∞ ‡®ï‡©Å‡®ù ‡®á‡®∏ ‡®§‡®∞‡©ç‡®π‡®æ‡®Ç ‡®∞‡©Ç‡®™‡®æ‡®Ç‡®§‡®∞‡®ø‡®§ ‡®ï‡®∞‡®® ‡®¶‡©Ä ‡®≤‡©ã‡©ú ‡®π‡©à ‡®ú‡©ã LLM ‡®®‡©Ç‡©∞ ‡®∏‡®Æ‡®ù ‡®Ü ‡®∏‡®ï‡©á‡•§

## ‡®®‡®Æ‡©Ç‡®®‡©á

- [Java Calculator](../samples/java/calculator/README.md)
- [.Net Calculator](../../../../03-GettingStarted/samples/csharp)
- [JavaScript Calculator](../samples/javascript/README.md)
- [TypeScript Calculator](../samples/typescript/README.md)
- [Python Calculator](../../../../03-GettingStarted/samples/python)
- [Rust Calculator](../../../../03-GettingStarted/samples/rust)

## ‡®µ‡®æ‡®ß‡©Ç ‡®∏‡®∞‡©ã‡®§

## ‡®Ö‡®ó‡®≤‡®æ ‡®ï‡©Ä ‡®π‡©à

- ‡®Ö‡®ó‡®≤‡®æ: [Visual Studio Code ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®∏‡®∞‡®µ‡®∞ ‡®®‡©Ç‡©∞ ‡®ï‡®®‡®ú‡®º‡®ø‡®ä‡®Æ ‡®ï‡®∞‡®®‡®æ](../04-vscode/README.md)

---

**‡®Ö‡®∏‡®µ‡©Ä‡®ï‡®∞‡®§‡©Ä**:  
‡®á‡®π ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º AI ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®∏‡©á‡®µ‡®æ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®ï‡©Ä‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à‡•§ ‡®π‡®æ‡®≤‡®æ‡®Ç‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®π‡©Ä ‡®π‡©ã‡®£ ‡®¶‡®æ ‡®Ø‡®§‡®® ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç, ‡®ï‡®ø‡®∞‡®™‡®æ ‡®ï‡®∞‡®ï‡©á ‡®ß‡®ø‡®Ü‡®® ‡®¶‡®ø‡®ì ‡®ï‡®ø ‡®∏‡®µ‡©à‡®ö‡®æ‡®≤‡®ø‡®§ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®ó‡®≤‡®§‡©Ä‡®Ü‡®Ç ‡®ú‡®æ‡®Ç ‡®Ö‡®∏‡©Å‡®ö‡©Ä‡®§‡®§‡®æ‡®µ‡®æ‡®Ç ‡®π‡©ã ‡®∏‡®ï‡®¶‡©Ä‡®Ü‡®Ç ‡®π‡®®‡•§ ‡®á‡®∏ ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º ‡®¶‡©á ‡®Æ‡©Ç‡®≤ ‡®≠‡®æ‡®∏‡®º‡®æ ‡®µ‡®ø‡©±‡®ö ‡®≤‡®ø‡®ñ‡©á ‡®ó‡©ç‡®∞‡©∞‡®• ‡®®‡©Ç‡©∞ ‡®Ö‡®ß‡®ø‡®ï‡®æ‡®∞‡®§ ‡®∏‡®∞‡©ã‡®§ ‡®Æ‡©∞‡®®‡®ø‡®Ü ‡®ú‡®æ‡®£‡®æ ‡®ö‡®æ‡®π‡©Ä‡®¶‡®æ ‡®π‡©à‡•§ ‡®Æ‡®π‡©±‡®§‡®µ‡®™‡©Ç‡®∞‡®® ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®≤‡®à, ‡®™‡©á‡®∏‡®º‡©á‡®µ‡®∞ ‡®Æ‡®®‡©Å‡©±‡®ñ‡©Ä ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®∏‡®ø‡®´‡®æ‡®∞‡®∏‡®º ‡®ï‡©Ä‡®§‡©Ä ‡®ú‡®æ‡®Ç‡®¶‡©Ä ‡®π‡©à‡•§ ‡®á‡®∏ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®§‡©ã‡®Ç ‡®™‡©à‡®¶‡®æ ‡®π‡©ã‡®£ ‡®µ‡®æ‡®≤‡©á ‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®ó‡®≤‡®§‡®´‡®π‡®ø‡®Æ‡©Ä ‡®ú‡®æ‡®Ç ‡®ó‡®≤‡®§ ‡®µ‡®ø‡®Ü‡®ñ‡®ø‡®Ü ‡®≤‡®à ‡®Ö‡®∏‡©Ä‡®Ç ‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞ ‡®®‡®π‡©Ä‡®Ç ‡®π‡®æ‡®Ç‡•§